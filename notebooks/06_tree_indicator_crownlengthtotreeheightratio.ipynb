{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e74759ab",
   "metadata": {},
   "source": [
    "# Crown length to tree height ratio Estimation from RGB Images\n",
    "\n",
    "This notebook computes **crown length to tree height ratio** from RGB images and optional segmentation masks.\n",
    "\n",
    "## Model\n",
    "The trained model (UNet ResNet50 Model Weights for Tree Health RGB Segmentation (v1.0)) can be downloaded from Zenodo: https://zenodo.org/records/18709178.\n",
    "After downloading, place the model in a folder 'model'\n",
    "\n",
    "## Local data\n",
    "\n",
    "The model need RGB tree images having size 256 x 256 pixels. The full dataset cannot be redistributed. Partial dataset is publically available at . Please download the dataset and set the paths in the configuration cell below. Users can use their own dataset as well\n",
    "\n",
    "## Outputs\n",
    "\n",
    "All outputs should be written into the output folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44792816-5662-4261-b29f-e1de29fe7719",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Import Libraries and Configure folder paths<DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6a068b-07d1-4c5c-acb1-ba0f69351edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------\n",
    "# Configuration (edit these)\n",
    "# -------------------------\n",
    "DATA_DIR = Path(\"images\")                 # original images \n",
    "MODEL_PATH = Path(\"model/unet_resnet50_ash_tree_segmentation.hdf5\")      # trained model path\n",
    "OUT_DIR = Path(\"outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMG_GLOB = \"*.jpg\"                             # or \"*.png\"\n",
    "TARGET_SIZE = 256                              # model input size\n",
    "\n",
    "# Class mapping (edit if different)\n",
    "# 0 background, 1 foliage, 2 wood, 3 ivy\n",
    "FOLIAGE_CLASS = 1\n",
    "WOOD_CLASS = 2\n",
    "\n",
    "# Output folders used by this notebook\n",
    "RESIZE_DIR  = OUT_DIR / \"resize\"\n",
    "PRED_DIR     = OUT_DIR / \"prediction\"\n",
    "UPSCALE_DIR  = OUT_DIR / \"upscaled\"\n",
    "CONTOUR_DIR  = OUT_DIR / \"OutermostContour\"\n",
    "INTERSECT_PRED_CONT_DIR = OUT_DIR / \"intersectpredictionCont\"\n",
    "TRUNK_TRUNCATE_DIR = OUT_DIR / \"trunktruncated\"\n",
    "TRUNK_TRUNCATE_CONT_DIR = OUT_DIR / \"trunktruncatedContour\"\n",
    "\n",
    "for d in [RESIZE_DIR, PRED_DIR, UPSCALE_DIR, CONTOUR_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"DATA_DIR:\", DATA_DIR.resolve())\n",
    "print(\"OUT_DIR :\", OUT_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d51538-7563-4228-a699-1f5cc3cfa8bb",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Resize All Image in a Folder<DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84e0a67-4dcc-4566-9efa-c0dce552d985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use configuration variables\n",
    "input_folder = DATA_DIR\n",
    "output_folder = RESIZE_DIR\n",
    "new_size = (TARGET_SIZE, TARGET_SIZE)\n",
    "\n",
    "# Path for storing original sizes\n",
    "sizes_path = OUT_DIR / \"original_sizes.json\"\n",
    "\n",
    "# Collect original sizes: key = original filename, value = [H, W]\n",
    "size_map = {}\n",
    "\n",
    "# Iterate over all folders and files in the input folder\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    root = Path(root)\n",
    "\n",
    "    for file in files:\n",
    "        if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            in_path = root / file\n",
    "\n",
    "            with Image.open(in_path) as im:\n",
    "                # Record original size (PIL gives (W, H))\n",
    "                orig_w, orig_h = im.size\n",
    "                size_map[in_path.name] = [int(orig_h), int(orig_w)]\n",
    "\n",
    "                # Resize to model input size\n",
    "                im_resized = im.resize(new_size)\n",
    "\n",
    "                # Preserve subfolder structure\n",
    "                rel_dir = in_path.parent.relative_to(input_folder)\n",
    "                out_dir = output_folder / rel_dir\n",
    "                out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                out_path = out_dir / (in_path.stem + \".png\")\n",
    "                im_resized.save(out_path)\n",
    "\n",
    "# Save original size map for upscaling step\n",
    "with open(sizes_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(size_map, f, indent=2)\n",
    "\n",
    "print(\"Saved resized images to:\", output_folder.resolve())\n",
    "print(\"Saved original sizes to:\", sizes_path.resolve())\n",
    "print(\"Example entry:\", next(iter(size_map.items())) if size_map else \"No images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ed4dfa-ea1f-4f31-b0df-d86fc2bd40d6",
   "metadata": {},
   "source": [
    "## <font color=darkgreen>Load Model<DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a986320f-e396-48f3-a8ba-da3636fcf38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the trained moel\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a404fb-67da-4f76-b948-a6fa77dab289",
   "metadata": {},
   "source": [
    "## <font color=darkgreen>Make Predictions for All Images in a Folder and subfolders<DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f985f29-c17b-4925-bfad-79ae4a41fe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = RESIZE_DIR\n",
    "output_folder = PRED_DIR\n",
    "\n",
    "# Iterate over all folders and files in the input folder\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    for file in files:\n",
    "        # Check if the file is an image\n",
    "        if file.endswith(\".JPG\") or file.endswith(\".png\"):\n",
    "            # Load the image\n",
    "            im = cv2.imread(os.path.join(root, file))\n",
    "            \n",
    "            # make the prediction\n",
    "            test_img = np.expand_dims(im, 0)\n",
    "            pred = model.predict(test_img)\n",
    "            predict = np.argmax(pred, axis=3)[0,:,:]\n",
    "            \n",
    "            predict_path = os.path.join(output_folder, os.path.relpath(root, input_folder), file[:-4]+'.png')\n",
    "            os.makedirs(os.path.dirname(predict_path), exist_ok=True)\n",
    "            cv2.imwrite(predict_path, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d818431",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Display Resized Image and Prediction<DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32f7b9-c6a4-4fd7-8f52-2d6561695be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Discrete colour scheme\n",
    "cmap = ListedColormap([\"whitesmoke\", \"limegreen\", \"peru\", \"darkgreen\"])\n",
    "\n",
    "# Choose which image to display\n",
    "idx = 4  # change index to view different image\n",
    "\n",
    "# Get corresponding resized image and prediction\n",
    "resized_images = sorted(RESIZE_DIR.rglob(\"*.png\"))\n",
    "predicted_masks = sorted(PRED_DIR.rglob(\"*.png\"))\n",
    "\n",
    "if not resized_images:\n",
    "    raise FileNotFoundError(f\"No resized images found in {RESIZE_DIR}\")\n",
    "\n",
    "img_path = resized_images[idx]\n",
    "pred_path = PRED_DIR / img_path.relative_to(RESIZE_DIR)\n",
    "\n",
    "if not pred_path.exists():\n",
    "    raise FileNotFoundError(f\"Prediction not found for {img_path.name}\")\n",
    "\n",
    "# Load images\n",
    "img = Image.open(img_path)\n",
    "pred = Image.open(pred_path)\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Resized image (256Ã—256)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(pred, cmap=cmap, vmin=0, vmax=3)\n",
    "plt.title(\"Predicted mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Displayed:\", img_path.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce81ea2-befc-40a6-b2f1-dd8d6e6961cb",
   "metadata": {},
   "source": [
    "## <font color=blue>Upscale Predicted Masks back to Original Size<DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b6eab2-b0ed-488f-8746-8e6ba0ef39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upscale predicted masks back to original image sizes (nearest neighbour)\n",
    "\n",
    "# Load original sizes (written during resizing step).\n",
    "sizes_path = OUT_DIR / \"original_sizes.json\"\n",
    "if not sizes_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"{sizes_path} not found. Run the resize step first so original sizes are recorded.\"\n",
    "    )\n",
    "\n",
    "with open(sizes_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    size_map = json.load(f)\n",
    "\n",
    "pred_mask_paths = sorted(PRED_DIR.glob(\"*.png\"))\n",
    "if not pred_mask_paths:\n",
    "    raise FileNotFoundError(f\"No predicted masks found in {PRED_DIR}. Run prediction step first.\")\n",
    "\n",
    "n_ok = 0\n",
    "for mask_path in pred_mask_paths:\n",
    "    # Assumes mask filename matches original image stem\n",
    "    # Example: IMG_001.jpg -> prediction/IMG_001.png\n",
    "    stem = mask_path.stem\n",
    "\n",
    "    # Find matching original image name by stem\n",
    "    # Works for jpg/png/jpeg\n",
    "    matches = [k for k in size_map.keys() if Path(k).stem == stem]\n",
    "    if not matches:\n",
    "        print(\"No original size entry for:\", stem, \"skipping\")\n",
    "        continue\n",
    "\n",
    "    orig_name = matches[0]\n",
    "    orig_h, orig_w = size_map[orig_name]\n",
    "\n",
    "    mask_small = cv2.imread(str(mask_path), cv2.IMREAD_UNCHANGED)\n",
    "    if mask_small is None:\n",
    "        print(\"Unreadable mask:\", mask_path.name, \"skipping\")\n",
    "        continue\n",
    "\n",
    "    mask_up = cv2.resize(mask_small, (int(orig_w), int(orig_h)), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    out_path = UPSCALE_DIR / mask_path.name\n",
    "    cv2.imwrite(str(out_path), mask_up)\n",
    "    n_ok += 1\n",
    "\n",
    "print(\"Upscaled masks written to:\", UPSCALE_DIR)\n",
    "print(\"Upscaled count:\", n_ok)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55579bec-0e0c-422f-9b54-81e70ed6e234",
   "metadata": {},
   "source": [
    "## <font color=blue>Display Original Image and Upscaled Prediction<DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2cfd13-d039-4b6f-865b-f34bfd1bfccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Discrete colour scheme\n",
    "cmap = ListedColormap([\"whitesmoke\", \"limegreen\", \"peru\", \"darkgreen\"])\n",
    "\n",
    "# Choose which image to display\n",
    "idx = 4  # change index to view different image\n",
    "\n",
    "# Get corresponding original image and upscaled predicted masks\n",
    "images = sorted(DATA_DIR.rglob(\"*.png\"))\n",
    "predicted_masks = sorted(UPSCALE_DIR.rglob(\"*.png\"))\n",
    "\n",
    "if not images:\n",
    "    raise FileNotFoundError(f\"No images found in {DATA_DIR}\")\n",
    "\n",
    "img_path = images[idx]\n",
    "upscale_path = UPSCALE_DIR / img_path.relative_to(DATA_DIR)\n",
    "\n",
    "if not upscale_path.exists():\n",
    "    raise FileNotFoundError(f\"Prediction not found for {img_path.name}\")\n",
    "\n",
    "# Load images\n",
    "img = Image.open(img_path)\n",
    "upscale = Image.open(upscale_path)\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(upscale, cmap=cmap, vmin=0, vmax=3)\n",
    "plt.title(\"Upscaled Predicted mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Displayed:\", img_path.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6887b0f7",
   "metadata": {},
   "source": [
    "## <font color=blue>Outermost Contour<DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "741ee217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "input_folder = UPSCALE_DIR\n",
    "output_folder = CONTOUR_DIR\n",
    "\n",
    "# Function to process the image and save the modified version\n",
    "def process_image(image_path):\n",
    "    # Load the segmented image\n",
    "    im = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the segmented image to numpy array\n",
    "    im = np.array(im)\n",
    "\n",
    "    # Create a binary image based on three classes i.e., foliage, wood, and ivy\n",
    "    single = im.copy()\n",
    "    single[(single==2) | (single==3)]=1\n",
    "\n",
    "    # Convert image to binary\n",
    "    single_gray = cv2.cvtColor(single, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, hierarchy = cv2.findContours(single_gray, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Find the outermost contour with the largest area\n",
    "    outer_contour = None\n",
    "    max_area = 0\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > max_area:\n",
    "            max_area = area\n",
    "            outer_contour = contour\n",
    "\n",
    "    # Check if outer_contour is not None\n",
    "    if outer_contour is not None:\n",
    "        # Approximate the outermost contour with a polygon\n",
    "        tolerance = 0.000001 * cv2.arcLength(outer_contour, True)\n",
    "        approx = cv2.approxPolyDP(outer_contour, tolerance, True)\n",
    "\n",
    "        # Create a new binary image with the polygonal approximation of the outermost contour\n",
    "        outermost_polygon_img = np.zeros_like(single_gray)\n",
    "        cv2.drawContours(outermost_polygon_img, [approx], -1, (255, 255, 255), -1)\n",
    "\n",
    "        # Change value from 255 to 1\n",
    "        outermost_polygon_img[outermost_polygon_img==255]=1\n",
    "\n",
    "        # Get the relative path within the input folder\n",
    "        relative_path = os.path.relpath(image_path, input_folder)\n",
    "\n",
    "        # Construct the output path with corresponding subfolders\n",
    "        output_subfolder = os.path.join(output_folder, os.path.dirname(relative_path))\n",
    "        os.makedirs(output_subfolder, exist_ok=True)\n",
    "        output_path = os.path.join(output_subfolder, os.path.basename(image_path))\n",
    "\n",
    "        # Save the modified image\n",
    "        cv2.imwrite(output_path, outermost_polygon_img)\n",
    "\n",
    "    else:\n",
    "        print(\"No contour found for file\", image_path)\n",
    "\n",
    "# Recursively process all files in the folder and subfolders\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    for file in files:\n",
    "        if file.endswith((\".JPG\", \".jpg\", \".png\")):\n",
    "            image_path = os.path.join(root, file)\n",
    "            process_image(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a041c98b",
   "metadata": {},
   "source": [
    "## <font color=blue>Display Image Prediction and Contour<DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10881f9-f1ae-4ea3-ac0d-548e87beb44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Discrete colour scheme\n",
    "cmap = ListedColormap([\"whitesmoke\", \"limegreen\", \"peru\", \"darkgreen\"])\n",
    "\n",
    "# Choose which image to display\n",
    "idx = 4  # change index to view different image\n",
    "\n",
    "# Get corresponding original image and upscaled predicted masks\n",
    "images = sorted(DATA_DIR.rglob(\"*.png\"))\n",
    "predicted_masks = sorted(UPSCALE_DIR.rglob(\"*.png\"))\n",
    "\n",
    "if not images:\n",
    "    raise FileNotFoundError(f\"No images found in {DATA_DIR}\")\n",
    "\n",
    "img_path = images[idx]\n",
    "upscale_path = UPSCALE_DIR / img_path.relative_to(DATA_DIR)\n",
    "cont_path = CONTOUR_DIR  / img_path.relative_to(DATA_DIR)\n",
    "\n",
    "if not upscale_path.exists():\n",
    "    raise FileNotFoundError(f\"Upscaled Prediction not found for {img_path.name}\")\n",
    "\n",
    "if not cont_path.exists():\n",
    "    raise FileNotFoundError(f\"Outermost Contour not found for {img_path.name}\")\n",
    "    \n",
    "# Load images\n",
    "img = Image.open(img_path)\n",
    "upscale = Image.open(upscale_path)\n",
    "cont = Image.open(cont_path)\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(upscale, cmap=cmap, vmin=0, vmax=3)\n",
    "plt.title(\"Upscaled Predicted mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(cont, cmap=cmap, vmin=0, vmax=3)\n",
    "plt.title(\"Outermost Contour\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Displayed:\", img_path.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4d7518",
   "metadata": {},
   "source": [
    "## <font color=blue>Intersect Prediction Contour<DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae65d4-308e-4f29-ab25-90f57e8e00c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "folder_path = UPSCALE_DIR                  # upscaled prediction masks (folder)\n",
    "contour_folder = CONTOUR_DIR               # contour images (folder)\n",
    "output_folder = INTERSECT_PRED_CONT_DIR    # output folder\n",
    "\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# List mask files from UPSCALE_DIR (use png only)\n",
    "image_files = sorted(folder_path.glob(\"*.png\"))\n",
    "if not image_files:\n",
    "    raise FileNotFoundError(f\"No .png files found in {folder_path}\")\n",
    "\n",
    "n_ok = 0\n",
    "n_missing_contour = 0\n",
    "\n",
    "for fol_path in image_files:\n",
    "    # contour file is expected to have the same name in CONTOUR_DIR\n",
    "    cont_path = contour_folder / fol_path.name\n",
    "\n",
    "    if not cont_path.exists():\n",
    "        n_missing_contour += 1\n",
    "        # If you want, print missing files:\n",
    "        # print(\"Missing contour for:\", fol_path.name)\n",
    "        continue\n",
    "\n",
    "    fol = Image.open(fol_path)\n",
    "    cont = Image.open(cont_path)\n",
    "\n",
    "    fol_array = np.array(fol)\n",
    "    cont_array = np.array(cont)\n",
    "\n",
    "    # Intersection: keep original fol values where contour > 0, else 0\n",
    "    intersection_array = np.where(cont_array > 0, fol_array, 0).astype(fol_array.dtype)\n",
    "\n",
    "    intersection_image = Image.fromarray(intersection_array)\n",
    "\n",
    "    out_path = output_folder / fol_path.name\n",
    "    intersection_image.save(out_path)\n",
    "    n_ok += 1\n",
    "\n",
    "print(\"Saved intersection outputs to:\", output_folder.resolve())\n",
    "print(\"Done:\", n_ok)\n",
    "print(\"Missing contour files:\", n_missing_contour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad01023",
   "metadata": {},
   "source": [
    "## <font color=blue>Display Intersected (Upscaled Prediction - Outermost Contour) Image<DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e99dc20-08a6-4989-949c-1d0eee61ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Discrete colour scheme\n",
    "cmap = ListedColormap([\"whitesmoke\", \"limegreen\", \"peru\", \"darkgreen\"])\n",
    "\n",
    "# Choose which image to display\n",
    "idx = 4  # change index to view different image\n",
    "\n",
    "# Get corresponding original image and upscaled predicted masks\n",
    "images = sorted(DATA_DIR.rglob(\"*.png\"))\n",
    "predicted_masks = sorted(UPSCALE_DIR.rglob(\"*.png\"))\n",
    "\n",
    "if not images:\n",
    "    raise FileNotFoundError(f\"No images found in {DATA_DIR}\")\n",
    "\n",
    "img_path = images[idx]\n",
    "upscale_path = UPSCALE_DIR / img_path.relative_to(DATA_DIR)\n",
    "cont_path = CONTOUR_DIR  / img_path.relative_to(DATA_DIR)\n",
    "intersect_path = INTERSECT_PRED_CONT_DIR / img_path.relative_to(DATA_DIR)\n",
    "\n",
    "if not upscale_path.exists():\n",
    "    raise FileNotFoundError(f\"Upscaled Prediction not found for {img_path.name}\")\n",
    "\n",
    "if not cont_path.exists():\n",
    "    raise FileNotFoundError(f\"Outermost Contour not found for {img_path.name}\")\n",
    "\n",
    "if not intersect_path.exists():\n",
    "    raise FileNotFoundError(f\"Intersected Mask not found for {img_path.name}\")\n",
    "    \n",
    "# Load images\n",
    "img = Image.open(img_path)\n",
    "upscale = Image.open(upscale_path)\n",
    "cont = Image.open(cont_path)\n",
    "intersect = Image.open(intersect_path)\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(upscale, cmap=cmap, vmin=0, vmax=3)\n",
    "plt.title(\"Upscaled Predicted mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(cont, cmap=cmap, vmin=0, vmax=3)\n",
    "plt.title(\"Outermost Contour\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(intersect, cmap=cmap, vmin=0, vmax=3)\n",
    "plt.title(\"Intersected Mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Displayed:\", img_path.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0b79b2-242b-4910-81bb-6d8b9b1f3b98",
   "metadata": {},
   "source": [
    "## <font color=blue>Tree Height (pixels) Estimation <DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f596598f-93d6-4d76-8c09-3009bc72fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "image_dir = INTERSECT_PRED_CONT_DIR\n",
    "csv_file = OUT_DIR / \"treeheight.csv\"\n",
    "\n",
    "# Write header once\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"image_name\", \"tree_height_pixels\"])\n",
    "\n",
    "# Process each PNG file\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.lower().endswith(\".png\"):\n",
    "\n",
    "        img_path = image_dir / filename\n",
    "        img = Image.open(img_path)\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        # Find rows containing any non-zero pixel\n",
    "        rows_with_tree = np.any(img_array != 0, axis=1)\n",
    "\n",
    "        if not np.any(rows_with_tree):\n",
    "            TreeHeight = 0\n",
    "        else:\n",
    "            first_nonzero_row = np.argmax(rows_with_tree)\n",
    "            last_nonzero_row = len(rows_with_tree) - np.argmax(rows_with_tree[::-1]) - 1\n",
    "            TreeHeight = last_nonzero_row - first_nonzero_row\n",
    "\n",
    "        # Append result\n",
    "        with open(csv_file, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([filename, TreeHeight])\n",
    "\n",
    "print(\"Processing complete.\")\n",
    "print(\"Results saved to:\", csv_file.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41960699-5024-408e-a814-1d9b8047d5a3",
   "metadata": {},
   "source": [
    "## <font color=blue>Trunk Truncation <DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "068ac110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set the path to the folder containing upscaled predicted images\n",
    "folder_path = INTERSECT_PRED_CONT_DIR\n",
    "\n",
    "# Set the path to the folder where modified images will be saved\n",
    "output_folder_path = TRUNK_TRUNCATE_DIR\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "# Function to process the image and save the modified version\n",
    "def process_image(image_path, output_folder):\n",
    "    # Load the predicted image\n",
    "    predicted_image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert image to grayscale\n",
    "    predicted_image_gray = cv2.cvtColor(predicted_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Scan the image from the bottom\n",
    "    desired_location = None\n",
    "    for y in range(predicted_image_gray.shape[0] - 1, -1, -1):\n",
    "        unique_classes = np.unique(predicted_image_gray[y])\n",
    "        if 1 in unique_classes and 2 in unique_classes:\n",
    "            desired_location = y\n",
    "            break\n",
    "\n",
    "    # Eliminate class 2 pixels from the bottom up to the desired location\n",
    "    if desired_location is not None:\n",
    "         # Get the indices where the pixel value is greater than 1\n",
    "        rows, cols = np.where(predicted_image_gray > 1)\n",
    "\n",
    "        # Filter out the rows starting from the desired location\n",
    "        filtered_cols = cols[rows >= desired_location]\n",
    "\n",
    "        # Eliminate class 2 pixels from the bottom up to the desired location\n",
    "        if desired_location is not None:\n",
    "            for col in filtered_cols:\n",
    "                predicted_image_gray[desired_location:, col] = 0\n",
    "\n",
    "    # Get the relative path within the input folder\n",
    "    relative_path = os.path.relpath(image_path, folder_path)\n",
    "\n",
    "    # Construct the output path with corresponding subfolders\n",
    "    output_subfolder = os.path.join(output_folder, os.path.dirname(relative_path))\n",
    "    os.makedirs(output_subfolder, exist_ok=True)\n",
    "    output_path = os.path.join(output_subfolder, os.path.basename(image_path))\n",
    "\n",
    "    # Save the modified image\n",
    "    cv2.imwrite(output_path, predicted_image_gray)\n",
    "\n",
    "# Recursively process all files in the folder and subfolders\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".png\"):\n",
    "            image_path = os.path.join(root, file)\n",
    "            process_image(image_path, output_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aec4a93-5877-46a5-9d75-43633b8030eb",
   "metadata": {},
   "source": [
    "## <font color=blue>Display Trunk Truncted Mask<DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895e6688-1fd1-4a78-a790-f15ad03200a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Discrete colour scheme\n",
    "cmap = ListedColormap([\"whitesmoke\", \"limegreen\", \"peru\", \"darkgreen\"])\n",
    "\n",
    "# Choose which image to display\n",
    "idx = 4  # change index to view different image\n",
    "\n",
    "# Get corresponding original image and upscaled predicted masks\n",
    "images = sorted(DATA_DIR.rglob(\"*.png\"))\n",
    "predicted_masks = sorted(UPSCALE_DIR.rglob(\"*.png\"))\n",
    "\n",
    "if not images:\n",
    "    raise FileNotFoundError(f\"No images found in {DATA_DIR}\")\n",
    "\n",
    "img_path = images[idx]\n",
    "upscale_path = UPSCALE_DIR / img_path.relative_to(DATA_DIR)\n",
    "cont_path = CONTOUR_DIR  / img_path.relative_to(DATA_DIR)\n",
    "intersect_path = INTERSECT_PRED_CONT_DIR / img_path.relative_to(DATA_DIR)\n",
    "truncated_path = TRUNK_TRUNCATE_DIR / img_path.relative_to(DATA_DIR)\n",
    "\n",
    "if not upscale_path.exists():\n",
    "    raise FileNotFoundError(f\"Upscaled Prediction not found for {img_path.name}\")\n",
    "\n",
    "if not cont_path.exists():\n",
    "    raise FileNotFoundError(f\"Outermost Contour not found for {img_path.name}\")\n",
    "\n",
    "if not intersect_path.exists():\n",
    "    raise FileNotFoundError(f\"Intersected Mask not found for {img_path.name}\")\n",
    "\n",
    "if not truncated_path.exists():\n",
    "    raise FileNotFoundError(f\"Trunk Truncated Mask not found for {img_path.name}\")\n",
    "    \n",
    "# Load images\n",
    "img = Image.open(img_path)\n",
    "upscale = Image.open(upscale_path)\n",
    "cont = Image.open(cont_path)\n",
    "intersect = Image.open(intersect_path)\n",
    "truncated = Image.open(truncated_path)\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "plt.subplot(1,5,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Original image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,5,2)\n",
    "plt.imshow(upscale, cmap=cmap, vmin=0, vmax=3)\n",
    "plt.title(\"Upscaled Predicted mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,5,3)\n",
    "plt.imshow(cont, cmap=cmap, vmin=0, vmax=3)\n",
    "plt.title(\"Outermost Contour\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,5,4)\n",
    "plt.imshow(intersect, cmap=cmap, vmin=0, vmax=3)\n",
    "plt.title(\"Intersected Mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,5,5)\n",
    "plt.imshow(truncated, cmap=cmap, vmin=0, vmax=3)\n",
    "plt.title(\"Trunk Truncated Mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Displayed:\", img_path.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8b710c-1688-4455-b41d-c067ae8ceaa9",
   "metadata": {},
   "source": [
    "## <font color=blue>Crown Length (pixels) Estimation<DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc14d03a-330e-43ec-8f3c-f4a6cad78e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = TRUNK_TRUNCATE_DIR\n",
    "csv_file = OUT_DIR / \"crownlength.csv\"\n",
    "\n",
    "# Write header once\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"image_name\", \"crown_length_pixels\"])\n",
    "\n",
    "# Process each PNG file\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.lower().endswith(\".png\"):\n",
    "\n",
    "        img_path = image_dir / filename\n",
    "        img = Image.open(img_path)\n",
    "        img_array = np.array(img)\n",
    "\n",
    "        # Find rows containing any non-zero pixel\n",
    "        rows_with_crown = np.any(img_array != 0, axis=1)\n",
    "\n",
    "        if not np.any(rows_with_crown):\n",
    "            CrownLength = 0\n",
    "        else:\n",
    "            first_nonzero_row = np.argmax(rows_with_crown)\n",
    "            last_nonzero_row = len(rows_with_crown) - np.argmax(rows_with_crown[::-1]) - 1\n",
    "            CrownLength = last_nonzero_row - first_nonzero_row\n",
    "\n",
    "        # Append result\n",
    "        with open(csv_file, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([filename, CrownLength])\n",
    "\n",
    "print(\"Processing complete.\")\n",
    "print(\"Results saved to:\", csv_file.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc033102-a1a6-44e3-a31f-0a730332e65d",
   "metadata": {},
   "source": [
    "## <font color=blue>Crown Length to Tree Height Ratio<DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1cc57c-be1a-4b9a-8b19-234e2ef5771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "treeheight_path = OUT_DIR / \"treeheight.csv\"\n",
    "crownlength_path = OUT_DIR / \"crownlength.csv\"\n",
    "output_path = OUT_DIR / \"crown_length_to_height_ratio.csv\"\n",
    "\n",
    "# Load CSV files\n",
    "df_height = pd.read_csv(treeheight_path)\n",
    "df_crown = pd.read_csv(crownlength_path)\n",
    "\n",
    "# Ensure consistent column names\n",
    "df_height.columns = [\"image_name\", \"tree_height_pixels\"]\n",
    "df_crown.columns = [\"image_name\", \"crown_length_pixels\", *df_crown.columns[2:]]\n",
    "\n",
    "# Merge on image_name\n",
    "df = pd.merge(df_height, df_crown[[\"image_name\", \"crown_length_pixels\"]],\n",
    "              on=\"image_name\",\n",
    "              how=\"inner\")\n",
    "\n",
    "# Avoid division by zero\n",
    "df[\"cl_th_ratio\"] = df.apply(\n",
    "    lambda row: row[\"crown_length_pixels\"] / row[\"tree_height_pixels\"]\n",
    "    if row[\"tree_height_pixels\"] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Save result\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Crown Length / Tree Height ratio saved to:\")\n",
    "print(output_path.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (latest Jaspy)",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
