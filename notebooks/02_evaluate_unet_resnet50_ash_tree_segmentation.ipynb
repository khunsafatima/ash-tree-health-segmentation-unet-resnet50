{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f6059d2",
   "metadata": {},
   "source": [
    "# Evaluatio of Trained Segmentation Model (UNet with ResNet50 Backbone)\n",
    "\n",
    "**Classes**:\n",
    "- 0: background\n",
    "- 1: foliage\n",
    "- 2: wood\n",
    "- 3: ivy\n",
    "\n",
    "## Data Required\n",
    "- You would need to provide test dataset:\n",
    "  * test\n",
    "    * images\n",
    "    * masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8797d106",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Import Libraries</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1dcf043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import rasterio\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42c44bf",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Configuration</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fde23ca-1da0-48e2-8664-a0f4c24ce699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Paths (edit for your local machine) ----\n",
    "DATA_DIR = Path(\"test\")     \n",
    "OUT_DIR  = Path(\"outputs_eval\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Make segmentation_models use tf.keras\n",
    "os.environ.setdefault(\"SM_FRAMEWORK\", \"tf.keras\")\n",
    "import segmentation_models as sm\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"segmentation_models:\", getattr(sm, \"__version__\", \"unknown\"))\n",
    "\n",
    "# Model / dataset settings\n",
    "BACKBONE = \"resnet50\"\n",
    "IMAGE_SIZE = 256\n",
    "N_CLASSES = 4\n",
    "\n",
    "# Visualisation\n",
    "N_EXAMPLES_TO_PLOT = 6\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1d4e41-7bde-4afb-935b-7f353574c01f",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Convert Dataset to Numpy Array</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b7509-4b8d-4867-9742-d18bd7a0eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"test\")\n",
    "IMAGE_DIR = DATA_DIR / \"images\"\n",
    "MASK_DIR  = DATA_DIR / \"masks\"\n",
    "\n",
    "IMAGE_SIZE = 256  # model input size\n",
    "\n",
    "image_paths = sorted(list(IMAGE_DIR.glob(\"*.png\")) + list(IMAGE_DIR.glob(\"*.jpg\")))\n",
    "\n",
    "X_test, y_true = [], []\n",
    "\n",
    "for img_path in image_paths:\n",
    "    # Try matching mask name: IMG_001.png -> IMG_001.tif\n",
    "    mask_path = MASK_DIR / f\"{img_path.stem}.tif\"\n",
    "    if not mask_path.exists():\n",
    "        alt = MASK_DIR / (img_path.name.rsplit(\".\", 1)[0] + \".tif\")\n",
    "        mask_path = alt if alt.exists() else mask_path\n",
    "\n",
    "    if not mask_path.exists():\n",
    "        print(\"Mask missing for:\", img_path.name)\n",
    "        continue\n",
    "\n",
    "    # --- image ---\n",
    "    img = cv2.imread(str(img_path), cv2.IMREAD_COLOR)\n",
    "    if img is None:\n",
    "        print(\"Unreadable image:\", img_path)\n",
    "        continue\n",
    "\n",
    "    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_AREA)\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "\n",
    "    # --- mask (GeoTIFF) ---\n",
    "    with rasterio.open(mask_path) as src:\n",
    "        mask = src.read(1)\n",
    "\n",
    "    mask = mask.astype(np.int64)\n",
    "    mask = cv2.resize(mask, (IMAGE_SIZE, IMAGE_SIZE),\n",
    "                      interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    X_test.append(img)\n",
    "    y_true.append(mask)\n",
    "\n",
    "# Convert to arrays\n",
    "X_test = np.stack(X_test, axis=0) if X_test else np.empty(\n",
    "    (0, IMAGE_SIZE, IMAGE_SIZE, 3), dtype=np.float32\n",
    ")\n",
    "\n",
    "y_true = np.stack(y_true, axis=0) if y_true else np.empty(\n",
    "    (0, IMAGE_SIZE, IMAGE_SIZE), dtype=np.int64\n",
    ")\n",
    "\n",
    "print(\"Loaded X_test:\", X_test.shape)\n",
    "print(\"Loaded y_true:\", y_true.shape)\n",
    "print(\"Unique labels in masks:\", np.unique(y_true) if y_true.size else \"None\")\n",
    "\n",
    "# Save arrays\n",
    "np.save(DATA_DIR / \"X_test.npy\", X_test)\n",
    "np.save(DATA_DIR / \"y_true.npy\", y_true)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(DATA_DIR / \"X_test.npy\")\n",
    "print(DATA_DIR / \"y_true.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aa9172-a945-4abc-888c-df30dbaf9e4a",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Display an Image and Mask from numoy arrays</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa99c2-ec69-47f0-97cc-567e09616b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discrete colour scheme\n",
    "cmap = ListedColormap([\"whitesmoke\", \"limegreen\", \"peru\", \"darkgreen\"])\n",
    "\n",
    "# Choose index\n",
    "idx = 1  # change index to view different image\n",
    "\n",
    "if idx >= len(X_test):\n",
    "    raise IndexError(f\"Index {idx} out of range. Max index = {len(X_test)-1}\")\n",
    "\n",
    "# Extract image and mask from numpy arrays\n",
    "img = X_test[idx]\n",
    "mask = y_true[idx]\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Test Image (256Ã—256)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(mask, cmap=cmap, vmin=0, vmax=3)\n",
    "plt.title(\"Ground Truth Mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Displayed index:\", idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a88046",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Load Trained Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96336e-34f9-42cd-8cba-b11d1b82fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MODEL_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Model not found: {MODEL_PATH.resolve()}\\n\"\n",
    "        \"Tip: download weights (from Zenodo) and place them under ./model/\"\n",
    "    )\n",
    "\n",
    "# If your model uses custom objects, add them here:\n",
    "CUSTOM_OBJECTS = {}\n",
    "\n",
    "# Model weights path (download separately hosted on Zenodo: https://zenodo.org/records/18709178)\n",
    "MODEL_PATH = Path(\"/gws/nopw/j04/nceo_digital_twin/TH/unet_resnet50_ash_tree_segmentation.hdf5\")\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_PATH, compile=False, custom_objects=CUSTOM_OBJECTS)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308692d1",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Predict</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf910bf-cab6-4206-974c-9ed107166df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "X_pp = preprocess_input(X_test)\n",
    "\n",
    "# Predict probabilities: (N,H,W,C)\n",
    "probs = model.predict(X_pp, batch_size=8, verbose=1)\n",
    "\n",
    "# Convert to predicted class labels: (N,H,W)\n",
    "y_pred = np.argmax(probs, axis=-1).astype(np.int32)\n",
    "print(\"y_pred:\", y_pred.shape, y_pred.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ec801",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Evaluation Metrics (per Class + Overall)</font>\n",
    "\n",
    "We compute pixel wise precision, recall, F1 and IoU per class, and overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c0cea-0449-48a7-9892-315a4e7afa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_class_metrics(y_true: np.ndarray, y_pred: np.ndarray, n_classes: int):\n",
    "    metrics = []\n",
    "    # Flatten for pixel-wise evaluation\n",
    "    yt = y_true.reshape(-1)\n",
    "    yp = y_pred.reshape(-1)\n",
    "\n",
    "    overall_acc = float((yt == yp).mean())\n",
    "\n",
    "    for c in range(n_classes):\n",
    "        tp = np.sum((yt == c) & (yp == c))\n",
    "        fp = np.sum((yt != c) & (yp == c))\n",
    "        fn = np.sum((yt == c) & (yp != c))\n",
    "\n",
    "        precision = tp / (tp + fp + 1e-12)\n",
    "        recall    = tp / (tp + fn + 1e-12)\n",
    "        f1        = 2 * precision * recall / (precision + recall + 1e-12)\n",
    "        iou       = tp / (tp + fp + fn + 1e-12)\n",
    "\n",
    "        metrics.append({\n",
    "            \"class\": c,\n",
    "            \"tp\": int(tp), \"fp\": int(fp), \"fn\": int(fn),\n",
    "            \"precision\": float(precision),\n",
    "            \"recall\": float(recall),\n",
    "            \"f1\": float(f1),\n",
    "            \"iou\": float(iou),\n",
    "        })\n",
    "\n",
    "    return overall_acc, pd.DataFrame(metrics)\n",
    "\n",
    "overall_acc, df = per_class_metrics(y_true, y_pred, N_CLASSES)\n",
    "\n",
    "display(df)\n",
    "print(\"Overall pixel accuracy:\", overall_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3504036b",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Save Results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a37d0c1-3d83-4a43-83bd-854f94b72b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"backbone\": BACKBONE,\n",
    "    \"image_size\": IMAGE_SIZE,\n",
    "    \"n_classes\": N_CLASSES,\n",
    "    \"overall_pixel_accuracy\": overall_acc,\n",
    "}\n",
    "\n",
    "df.to_csv(OUT_DIR / \"per_class_metrics.csv\", index=False)\n",
    "pd.DataFrame([results]).to_csv(OUT_DIR / \"summary_metrics.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"-\", (OUT_DIR / \"per_class_metrics.csv\").resolve())\n",
    "print(\"-\", (OUT_DIR / \"summary_metrics.csv\").resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c4898",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Visualise a Few Examples</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66f87cf-27d5-4167-9482-4574170e92d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "idx = rng.choice(len(X_test), size=min(N_EXAMPLES_TO_PLOT, len(X_test)), replace=False)\n",
    "\n",
    "def show_example(i: int):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    ax[0].imshow(X_test[i].astype(np.uint8))\n",
    "    ax[0].set_title(\"Input (RGB)\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    ax[1].imshow(y_true[i], vmin=0, vmax=N_CLASSES-1)\n",
    "    ax[1].set_title(\"Ground truth\")\n",
    "    ax[1].axis(\"off\")\n",
    "\n",
    "    ax[2].imshow(y_pred[i], vmin=0, vmax=N_CLASSES-1)\n",
    "    ax[2].set_title(\"Prediction\")\n",
    "    ax[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "for i in idx:\n",
    "    fig = show_example(int(i))\n",
    "    fig.savefig(OUT_DIR / f\"example_{int(i):04d}.png\", dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "print(f\"Saved {len(idx)} example figures to:\", OUT_DIR.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (latest Jaspy)",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
