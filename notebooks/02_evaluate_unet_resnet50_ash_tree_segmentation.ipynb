{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f6059d2",
   "metadata": {},
   "source": [
    "# Evaluatio of Trained Segmentation Model (UNet + ResNet50)\n",
    "\n",
    "**Classes** (example mapping):\n",
    "- 0: background\n",
    "- 1: foliage\n",
    "- 2: wood\n",
    "- 3: ivy\n",
    "\n",
    "## Notes\n",
    "- Provide your own local test arrays or image folders.\n",
    "- Expected NumPy shapes:\n",
    "  - `X_test`: `(N, 256, 256, 3)` RGB\n",
    "  - `y_test`: either `(N, 256, 256)` integer masks **or** `(N, 256, 256, 4)` one hot masks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8797d106",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dcf043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Make segmentation_models use tf.keras\n",
    "os.environ.setdefault(\"SM_FRAMEWORK\", \"tf.keras\")\n",
    "import segmentation_models as sm\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"segmentation_models:\", getattr(sm, \"__version__\", \"unknown\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42c44bf",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c98db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Paths (edit for your local machine) ----\n",
    "DATA_DIR = Path(\"data_private\")     # not committed to GitHub\n",
    "OUT_DIR  = Path(\"outputs_eval\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Model weights path (download separately hosted on Zenodo)\n",
    "MODEL_PATH = Path(\"model\") / \"unet_resnet50_ash_tree_segmentation.hdf5\"\n",
    "\n",
    "# Test set arrays (filenames are placeholders: rename to match your local files)\n",
    "X_TEST_NPY = DATA_DIR / \"X_test.npy\"\n",
    "Y_TEST_NPY = DATA_DIR / \"y_test.npy\"\n",
    "\n",
    "# Model / dataset settings\n",
    "BACKBONE = \"resnet50\"\n",
    "IMAGE_SIZE = 256\n",
    "N_CLASSES = 4\n",
    "\n",
    "# Visualisation\n",
    "N_EXAMPLES_TO_PLOT = 6\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a88046",
   "metadata": {},
   "source": [
    "## 3. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd626d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not MODEL_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Model not found: {MODEL_PATH.resolve()}\\n\"\n",
    "        \"Tip: download weights (from Zenodo) and place them under ./model/\"\n",
    "    )\n",
    "\n",
    "# If your model uses custom objects, add them here:\n",
    "CUSTOM_OBJECTS = {}\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_PATH, compile=False, custom_objects=CUSTOM_OBJECTS)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3467e0b",
   "metadata": {},
   "source": [
    "## 4. Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9bd4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy(path: Path) -> np.ndarray:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Missing file: {path.resolve()}\\n\"\n",
    "        )\n",
    "    return np.load(path)\n",
    "\n",
    "X_test = load_npy(X_TEST_NPY)\n",
    "y_test = load_npy(Y_TEST_NPY)\n",
    "\n",
    "print(\"X_test:\", X_test.shape, X_test.dtype)\n",
    "print(\"y_test:\", y_test.shape, y_test.dtype)\n",
    "\n",
    "# Basic checks\n",
    "if X_test.ndim != 4 or X_test.shape[-1] != 3:\n",
    "    raise ValueError(\"X_test must have shape (N, H, W, 3).\")\n",
    "\n",
    "if X_test.shape[1] != IMAGE_SIZE or X_test.shape[2] != IMAGE_SIZE:\n",
    "    raise ValueError(f\"Expected IMAGE_SIZE={IMAGE_SIZE}, got {X_test.shape[1:3]}.\")\n",
    "\n",
    "# Convert y to integer mask if needed\n",
    "if y_test.ndim == 4 and y_test.shape[-1] == N_CLASSES:\n",
    "    y_true = np.argmax(y_test, axis=-1).astype(np.int32)\n",
    "elif y_test.ndim == 3:\n",
    "    y_true = y_test.astype(np.int32)\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"y_test must be either (N,H,W) integer masks or (N,H,W,C) one-hot masks.\"\n",
    "    )\n",
    "\n",
    "print(\"y_true:\", y_true.shape, y_true.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308692d1",
   "metadata": {},
   "source": [
    "## 5. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a44c810",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = sm.get_preprocessing(BACKBONE)\n",
    "X_pp = preprocess_input(X_test)\n",
    "\n",
    "# Predict probabilities: (N,H,W,C)\n",
    "probs = model.predict(X_pp, batch_size=8, verbose=1)\n",
    "\n",
    "# Convert to predicted class labels: (N,H,W)\n",
    "y_pred = np.argmax(probs, axis=-1).astype(np.int32)\n",
    "print(\"y_pred:\", y_pred.shape, y_pred.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069ec801",
   "metadata": {},
   "source": [
    "## 6. Metrics (overall + per class)\n",
    "\n",
    "We compute pixel wise precision, recall, F1 and IoU per class, and overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac0051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_class_metrics(y_true: np.ndarray, y_pred: np.ndarray, n_classes: int):\n",
    "    metrics = []\n",
    "    # Flatten for pixel-wise evaluation\n",
    "    yt = y_true.reshape(-1)\n",
    "    yp = y_pred.reshape(-1)\n",
    "\n",
    "    overall_acc = float((yt == yp).mean())\n",
    "\n",
    "    for c in range(n_classes):\n",
    "        tp = np.sum((yt == c) & (yp == c))\n",
    "        fp = np.sum((yt != c) & (yp == c))\n",
    "        fn = np.sum((yt == c) & (yp != c))\n",
    "\n",
    "        precision = tp / (tp + fp + 1e-12)\n",
    "        recall    = tp / (tp + fn + 1e-12)\n",
    "        f1        = 2 * precision * recall / (precision + recall + 1e-12)\n",
    "        iou       = tp / (tp + fp + fn + 1e-12)\n",
    "\n",
    "        metrics.append({\n",
    "            \"class\": c,\n",
    "            \"tp\": int(tp), \"fp\": int(fp), \"fn\": int(fn),\n",
    "            \"precision\": float(precision),\n",
    "            \"recall\": float(recall),\n",
    "            \"f1\": float(f1),\n",
    "            \"iou\": float(iou),\n",
    "        })\n",
    "\n",
    "    return overall_acc, pd.DataFrame(metrics)\n",
    "\n",
    "overall_acc, df = per_class_metrics(y_true, y_pred, N_CLASSES)\n",
    "\n",
    "display(df)\n",
    "print(\"Overall pixel accuracy:\", overall_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3504036b",
   "metadata": {},
   "source": [
    "## 7. Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e73712",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"backbone\": BACKBONE,\n",
    "    \"image_size\": IMAGE_SIZE,\n",
    "    \"n_classes\": N_CLASSES,\n",
    "    \"overall_pixel_accuracy\": overall_acc,\n",
    "}\n",
    "\n",
    "df.to_csv(OUT_DIR / \"per_class_metrics.csv\", index=False)\n",
    "pd.DataFrame([results]).to_csv(OUT_DIR / \"summary_metrics.csv\", index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"-\", (OUT_DIR / \"per_class_metrics.csv\").resolve())\n",
    "print(\"-\", (OUT_DIR / \"summary_metrics.csv\").resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c4898",
   "metadata": {},
   "source": [
    "## 8. Visualise a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "idx = rng.choice(len(X_test), size=min(N_EXAMPLES_TO_PLOT, len(X_test)), replace=False)\n",
    "\n",
    "def show_example(i: int):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    ax[0].imshow(X_test[i].astype(np.uint8))\n",
    "    ax[0].set_title(\"Input (RGB)\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    ax[1].imshow(y_true[i], vmin=0, vmax=N_CLASSES-1)\n",
    "    ax[1].set_title(\"Ground truth\")\n",
    "    ax[1].axis(\"off\")\n",
    "\n",
    "    ax[2].imshow(y_pred[i], vmin=0, vmax=N_CLASSES-1)\n",
    "    ax[2].set_title(\"Prediction\")\n",
    "    ax[2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "for i in idx:\n",
    "    fig = show_example(int(i))\n",
    "    fig.savefig(OUT_DIR / f\"example_{int(i):04d}.png\", dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "print(f\"Saved {len(idx)} example figures to:\", OUT_DIR.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (latest Jaspy)",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
