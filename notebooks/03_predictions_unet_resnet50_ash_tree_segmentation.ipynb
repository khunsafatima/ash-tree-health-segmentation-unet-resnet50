{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18087325-1f91-44d2-aa42-3eb7ae769ffb",
   "metadata": {},
   "source": [
    "# Make Predictions (Segmentation) on RGB Tree Images using Trained UNet (with ResNet50 backbone) model\n",
    "\n",
    "This notebook can be used to get segmentation of RGB tree images.\n",
    "\n",
    "## Model\n",
    "The trained model (UNet ResNet50 Model Weights for Tree Health RGB Segmentation (v1.0)) can be downloaded from Zenodo: https://zenodo.org/records/18709178.\n",
    "After downloading, place the model in a folder 'model'\n",
    "\n",
    "## Input data\n",
    "\n",
    "The model need RGB tree images having size 256 x 256 pixels. The full dataset cannot be redistributed. Partial dataset is publically available at . Please download the dataset and set the paths in the configuration cell below. Users can use their own dataset as well\n",
    "\n",
    "## Outputs\n",
    "\n",
    "All outputs should be written into the output folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21b900a-69b0-4774-b754-d98235a0c6d7",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Import Libraries</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93625786-487e-4919-bd99-632fd9a76b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2c62f6-f1ae-4958-bbe9-356ac12cefdf",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Configure folder paths</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac223fe-2be8-4c30-8d68-143ae3d2250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Configuration (edit these)\n",
    "# -------------------------\n",
    "DATA_DIR = Path(\"images\")                 # original images \n",
    "MODEL_PATH = Path(\"model/unet_resnet50_ash_tree_segmentation.hdf5\")      # trained model path\n",
    "OUT_DIR = Path(\"outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMG_GLOB = \"*.jpg\"                             # or \"*.png\"\n",
    "TARGET_SIZE = 256                              # model input size\n",
    "\n",
    "# Class mapping\n",
    "# 0 background, 1 foliage, 2 wood, 3 ivy\n",
    "FOLIAGE_CLASS = 1\n",
    "WOOD_CLASS = 2\n",
    "IVY_CLASS = 3\n",
    "BACKGROUND_CLASS = 4\n",
    "\n",
    "# Output folders used by this notebook\n",
    "RESIZE_DIR  = OUT_DIR / \"resize\"\n",
    "PRED_DIR     = OUT_DIR / \"prediction\"\n",
    "\n",
    "for d in [RESIZE_DIR, PRED_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"DATA_DIR:\", DATA_DIR.resolve())\n",
    "print(\"OUT_DIR :\", OUT_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4896b056-14a8-4ec9-891e-fee99b52dc96",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Resize All Image in a Folder<DATA_DIR>\n",
    "### The model (UNet with ResNet50 backbone) accepts input RGB images with size 256 x 256 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048e376-a415-451c-a5f4-0f553375647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use configuration variables\n",
    "input_folder = DATA_DIR\n",
    "output_folder = RESIZE_DIR\n",
    "new_size = (TARGET_SIZE, TARGET_SIZE)\n",
    "\n",
    "# Path for storing original sizes\n",
    "sizes_path = OUT_DIR / \"original_sizes.json\"\n",
    "\n",
    "# Collect original sizes: key = original filename, value = [H, W]\n",
    "size_map = {}\n",
    "\n",
    "# Iterate over all folders and files in the input folder\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    root = Path(root)\n",
    "\n",
    "    for file in files:\n",
    "        if file.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "            in_path = root / file\n",
    "\n",
    "            with Image.open(in_path) as im:\n",
    "                # Record original size (PIL gives (W, H))\n",
    "                orig_w, orig_h = im.size\n",
    "                size_map[in_path.name] = [int(orig_h), int(orig_w)]\n",
    "\n",
    "                # Resize to model input size\n",
    "                im_resized = im.resize(new_size)\n",
    "\n",
    "                # Preserve subfolder structure\n",
    "                rel_dir = in_path.parent.relative_to(input_folder)\n",
    "                out_dir = output_folder / rel_dir\n",
    "                out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                out_path = out_dir / (in_path.stem + \".png\")\n",
    "                im_resized.save(out_path)\n",
    "\n",
    "# Save original size map for upscaling step\n",
    "with open(sizes_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(size_map, f, indent=2)\n",
    "\n",
    "print(\"Saved resized images to:\", output_folder.resolve())\n",
    "print(\"Saved original sizes to:\", sizes_path.resolve())\n",
    "print(\"Example entry:\", next(iter(size_map.items())) if size_map else \"No images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d1c42-3e33-4635-a0cc-1ba88619324a",
   "metadata": {},
   "source": [
    "## <font color=darkgreen>Load Model<DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c645d98-de0d-40c8-a9dc-9afa97b7a6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the trained moel\n",
    "model = tf.keras.models.load_model('model/unet_resnet50_ash_tree_segmentation.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51ec725-2cf8-415b-9103-f4590fae6579",
   "metadata": {},
   "source": [
    "## <font color=darkgreen>Make Predictions for All Images in a Folder and subfolders</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a18106-be78-4383-a448-22362182b7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = RESIZE_DIR\n",
    "output_folder = PRED_DIR\n",
    "\n",
    "# Iterate over all folders and files in the input folder\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    for file in files:\n",
    "        # Check if the file is an image\n",
    "        if file.endswith(\".JPG\") or file.endswith(\".png\"):\n",
    "            # Load the image\n",
    "            im = cv2.imread(os.path.join(root, file))\n",
    "            \n",
    "            # make the prediction\n",
    "            test_img = np.expand_dims(im, 0)\n",
    "            pred = model.predict(test_img)\n",
    "            predict = np.argmax(pred, axis=3)[0,:,:]\n",
    "            \n",
    "            predict_path = os.path.join(output_folder, os.path.relpath(root, input_folder), file[:-4]+'.png')\n",
    "            os.makedirs(os.path.dirname(predict_path), exist_ok=True)\n",
    "            cv2.imwrite(predict_path, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5958a01f-36bf-4dbd-890a-9b9be5a13bfc",
   "metadata": {},
   "source": [
    "## <font color=darkblue>Display a Resized Image and Prediction<DATA_DIR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb272be4-1665-46b8-b6b4-54b7bbb73514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "# Discrete colour scheme\n",
    "cmap = ListedColormap([\"whitesmoke\", \"limegreen\", \"peru\", \"darkgreen\"])\n",
    "\n",
    "# Choose which image to display\n",
    "idx = 1  # change index to view different image\n",
    "\n",
    "# Get corresponding resized image and prediction\n",
    "resized_images = sorted(RESIZE_DIR.rglob(\"*.png\"))\n",
    "predicted_masks = sorted(PRED_DIR.rglob(\"*.png\"))\n",
    "\n",
    "if not resized_images:\n",
    "    raise FileNotFoundError(f\"No resized images found in {RESIZE_DIR}\")\n",
    "\n",
    "img_path = resized_images[idx]\n",
    "pred_path = PRED_DIR / img_path.relative_to(RESIZE_DIR)\n",
    "\n",
    "if not pred_path.exists():\n",
    "    raise FileNotFoundError(f\"Prediction not found for {img_path.name}\")\n",
    "\n",
    "# Load images\n",
    "img = Image.open(img_path)\n",
    "pred = Image.open(pred_path)\n",
    "\n",
    "# Plot\n",
    "fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Resized image (256Ã—256)\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(pred, cmap=cmap, vmin=0, vmax=3)\n",
    "plt.title(\"Predicted mask\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Displayed:\", img_path.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (latest Jaspy)",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
